{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# E-learning Recommendation System\n", "\n", "This notebook demonstrates a recommendation system for personalized e-learning content using deep learning-based collaborative filtering.\n", "We cover:\n", "- Dataset preparation\n", "- User-Item matrix construction\n", "- Neural network model for collaborative filtering\n", "- Training and evaluation\n", "- Example recommendations"]}, {"cell_type": "code", "metadata": {}, "source": ["!pip install pandas numpy torch scikit-learn matplotlib seaborn"]}, {"cell_type": "code", "metadata": {}, "source": ["import pandas as pd\n", "import numpy as np\n", "import torch\n", "import torch.nn as nn\n", "from torch.utils.data import Dataset, DataLoader\n", "from sklearn.model_selection import train_test_split\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns"]}, {"cell_type": "code", "metadata": {}, "source": ["# Sample dataset\n", "data = {\n", "    'user_id': [1,1,2,2,3,3,4,4,5,5],\n", "    'item_id': [101,102,101,103,102,104,101,104,103,105],\n", "    'rating': [5,4,4,5,3,4,2,5,3,4]\n", "}\n", "df = pd.DataFrame(data)\ndf.head()"]}, {"cell_type": "code", "metadata": {}, "source": ["num_users = df['user_id'].nunique()\n", "num_items = df['item_id'].nunique()\n", "\n", "user_mapping = {id:i for i,id in enumerate(df['user_id'].unique())}\n", "item_mapping = {id:i for i,id in enumerate(df['item_id'].unique())}\n", "\n", "df['user_idx'] = df['user_id'].map(user_mapping)\n", "df['item_idx'] = df['item_id'].map(item_mapping)\n", "\n", "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"]}, {"cell_type": "code", "metadata": {}, "source": ["class RatingsDataset(Dataset):\n", "    def __init__(self, df):\n", "        self.users = torch.tensor(df['user_idx'].values)\n", "        self.items = torch.tensor(df['item_idx'].values)\n", "        self.ratings = torch.tensor(df['rating'].values, dtype=torch.float32)\n", "    def __len__(self):\n", "        return len(self.ratings)\n", "    def __getitem__(self, idx):\n", "        return self.users[idx], self.items[idx], self.ratings[idx]\n", "\n", "train_dataset = RatingsDataset(train_df)\n", "test_dataset = RatingsDataset(test_df)\n", "\n", "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n", "test_loader = DataLoader(test_dataset, batch_size=2)"]}, {"cell_type": "code", "metadata": {}, "source": ["class CFModel(nn.Module):\n", "    def __init__(self, num_users, num_items, embedding_size=8):\n", "        super(CFModel, self).__init__()\n", "        self.user_emb = nn.Embedding(num_users, embedding_size)\n", "        self.item_emb = nn.Embedding(num_items, embedding_size)\n", "        self.fc = nn.Linear(embedding_size, 1)\n", "    def forward(self, user, item):\n", "        u = self.user_emb(user)\n", "        i = self.item_emb(item)\n", "        x = u * i\n", "        return self.fc(x).squeeze()\n", "\n", "model = CFModel(num_users, num_items)\n", "criterion = nn.MSELoss()\n", "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"]}, {"cell_type": "code", "metadata": {}, "source": ["# Training\n", "epochs = 20\n", "for epoch in range(epochs):\n", "    model.train()\n", "    total_loss = 0\n", "    for user, item, rating in train_loader:\n", "        optimizer.zero_grad()\n", "        pred = model(user, item)\n", "        loss = criterion(pred, rating)\n", "        loss.backward()\n", "        optimizer.step()\n", "        total_loss += loss.item()\n", "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")"]}, {"cell_type": "code", "metadata": {}, "source": ["# Evaluation\n", "model.eval()\n", "preds, actuals = [], []\n", "with torch.no_grad():\n", "    for user, item, rating in test_loader:\n", "        pred = model(user, item)\n", "        preds.extend(pred.tolist())\n", "        actuals.extend(rating.tolist())\n", "\n", "mse = np.mean((np.array(preds) - np.array(actuals))**2)\n", "print(f\"Test MSE: {mse:.4f}\")"]}, {"cell_type": "code", "metadata": {}, "source": ["# Generate Recommendations for a user\n", "user_id = 1\n", "user_idx = user_mapping[user_id]\n", "item_indices = torch.tensor([i for i in range(num_items)])\n", "user_tensor = torch.tensor([user_idx]*num_items)\n", "\n", "model.eval()\n", "with torch.no_grad():\n", "    scores = model(user_tensor, item_indices).numpy()\n", "\n", "recommended_items = [k for k,v in sorted(zip(item_mapping.keys(), scores), key=lambda x: -x[1])]\n", "print(f\"Recommended items for user {user_id}: {recommended_items[:3]}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Conclusion\n", "This notebook demonstrates a full pipeline for building a deep learning-based collaborative filtering recommendation system:\n", "- User and item embeddings learned from data\n", "- Predictions of user preferences\n", "- Generating personalized recommendations\n", "- Pipeline is ready for larger datasets and production"]}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3"}, "language_info": {"name": "python", "version": "3.11"}}, "nbformat": 4, "nbformat_minor": 5}
