{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# E-learning Recommendation System\n",
        "\n",
        "This notebook demonstrates a recommendation system for personalized e-learning content using deep learning-based collaborative filtering.\n",
        "We cover:\n",
        "- Dataset preparation\n",
        "- User-Item matrix construction\n",
        "- Neural network model for collaborative filtering\n",
        "- Training and evaluation\n",
        "- Example recommendations\n"
      ],
      "metadata": {
        "id": "yTfW0lNOrQsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy torch scikit-learn matplotlib seaborn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "Vo_hFt0wrRy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data\n",
        "data = {\n",
        "    'user_id': [1,1,2,2,3,3,4,4,5,5],\n",
        "    'item_id': [101,102,101,103,102,104,101,104,103,105],\n",
        "    'rating': [5,4,4,5,3,4,2,5,3,4]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "um39iDmDrUUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_users = df['user_id'].nunique()\n",
        "num_items = df['item_id'].nunique()\n",
        "\n",
        "user_mapping = {id:i for i,id in enumerate(df['user_id'].unique())}\n",
        "item_mapping = {id:i for i,id in enumerate(df['item_id'].unique())}\n",
        "\n",
        "df['user_idx'] = df['user_id'].map(user_mapping)\n",
        "df['item_idx'] = df['item_id'].map(item_mapping)\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "ywDMgNsVrX_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RatingsDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.users = torch.tensor(df['user_idx'].values)\n",
        "        self.items = torch.tensor(df['item_idx'].values)\n",
        "        self.ratings = torch.tensor(df['rating'].values, dtype=torch.float32)\n",
        "    def __len__(self):\n",
        "        return len(self.ratings)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.users[idx], self.items[idx], self.ratings[idx]\n",
        "\n",
        "train_dataset = RatingsDataset(train_df)\n",
        "test_dataset = RatingsDataset(test_df)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=2)\n"
      ],
      "metadata": {
        "id": "FGR-q-F1raOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CFModel(nn.Module):\n",
        "    def __init__(self, num_users, num_items, embedding_size=8):\n",
        "        super(CFModel, self).__init__()\n",
        "        self.user_emb = nn.Embedding(num_users, embedding_size)\n",
        "        self.item_emb = nn.Embedding(num_items, embedding_size)\n",
        "        self.fc = nn.Linear(embedding_size, 1)\n",
        "    def forward(self, user, item):\n",
        "        u = self.user_emb(user)\n",
        "        i = self.item_emb(item)\n",
        "        x = u * i\n",
        "        return self.fc(x).squeeze()\n",
        "\n",
        "model = CFModel(num_users, num_items)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n"
      ],
      "metadata": {
        "id": "K2Ai9iDrra4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for user, item, rating in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(user, item)\n",
        "        loss = criterion(pred, rating)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "id": "Z0Om07eyrck2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "preds, actuals = [], []\n",
        "with torch.no_grad():\n",
        "    for user, item, rating in test_loader:\n",
        "        pred = model(user, item)\n",
        "        preds.extend(pred.tolist())\n",
        "        actuals.extend(rating.tolist())\n",
        "\n",
        "mse = np.mean((np.array(preds) - np.array(actuals))**2)\n",
        "print(f\"Test MSE: {mse:.4f}\")\n"
      ],
      "metadata": {
        "id": "DZrbnTO3reP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 1  # example\n",
        "user_idx = user_mapping[user_id]\n",
        "item_indices = torch.tensor([i for i in range(num_items)])\n",
        "user_tensor = torch.tensor([user_idx]*num_items)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    scores = model(user_tensor, item_indices).numpy()\n",
        "\n",
        "recommended_items = [k for k,v in sorted(zip(item_mapping.keys(), scores), key=lambda x: -x[1])]\n",
        "print(f\"Recommended items for user {user_id}: {recommended_items[:3]}\")\n"
      ],
      "metadata": {
        "id": "DsIzcfZKrkH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook demonstrates a full pipeline for building a deep learning-based collaborative filtering recommendation system:\n",
        "- User and item embeddings learned from data\n",
        "- Predictions of user preferences\n",
        "- Generating personalized recommendations\n",
        "- Pipeline is ready for larger datasets and production\n"
      ],
      "metadata": {
        "id": "vI2W7_tKrl3P"
      }
    }
  ]
}
